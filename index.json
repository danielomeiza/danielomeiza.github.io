[{"authors":null,"categories":null,"content":"I am postdoctoral researcher at the Oxford Robotics Institute (ORI) where I research explainability in robotic systems. I am also developing new quantitative metrics for assessing the overall health of autonomous driving agents. I have spent the past 5 years as an active machine learning and explainable AI researcher across organisations such as the University of Oxford, Carnegie Mellon University, and IBM Research. During my PhD in CS at Oxford University, I leveraged XAI and behavioural science theories to develop transparent algorithms for generating intelligible explanations in autonomous driving. These explanation techniques have been deployed within large projects like the SAX and the RAILS projects. I am also a musician and play the piano and a bunch of other musical instruments.\n  Download my CV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://danielomeiza.github.io/author/daniel-omeiza/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/daniel-omeiza/","section":"authors","summary":"I am postdoctoral researcher at the Oxford Robotics Institute (ORI) where I research explainability in robotic systems. I am also developing new quantitative metrics for assessing the overall health of autonomous driving agents.","tags":null,"title":"Daniel Omeiza","type":"authors"},{"authors":["Daniel Omeiza"],"categories":null,"content":"","date":1684281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685318400,"objectID":"fd458dd4e9ab01becea0e6abbe41d38f","permalink":"https://danielomeiza.github.io/post/final-thesis-available/","publishdate":"2023-05-17T00:00:00Z","relpermalink":"/post/final-thesis-available/","section":"post","summary":"My DPhil thesis on providing and assessing intelligible explanations is now available for download.","tags":null,"title":"My final DPhil thesis is now available for download","type":"post"},{"authors":["Pawit Kochakarn","Daniele De Martini","Daniel Omeiza","Lars Kunze"],"categories":null,"content":"","date":1684108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684108800,"objectID":"f555e5ea03371fc42bfafbf805c4174f","permalink":"https://danielomeiza.github.io/publication/001_a_scene_graphs/","publishdate":"2023-05-15T00:00:00Z","relpermalink":"/publication/001_a_scene_graphs/","section":"publication","summary":"This work explores scene graphs as a distille representation of high-level information for autonomous driving, applied to future driver-action prediction. Given the scarcity and strong imbalance of data samples, we propose a self-supervision pipeline to infer representative and well-separated embeddings. Key aspects are interpretability and explainability; as such, we embed in our architecture attention mechanisms that can create spatial and temporal heatmaps on the scene graphs. We evaluate our system on the ROAD dataset against a fully-supervised approach, showing the superiority of our training regime.","tags":null,"title":"Explainable Action Prediction through Self-Supervision on Scene Graphs","type":"publication"},{"authors":["Daniel Omeiza"],"categories":null,"content":"Overview I am co-organising the 1st International Workshop on Socially Interactive Autonomous Mobility (SIAM) at IV 2023. One of the goals of this workshop is to bridge the gap between Computational Cognitive and Behavior Science, Explainable AI, Transportation, and the Autonomous Driving community.\nRead more\n","date":1683849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684281600,"objectID":"b59fd2c86f07ff1803e6cb7bcb72d867","permalink":"https://danielomeiza.github.io/post/iv-workshop/","publishdate":"2023-05-12T00:00:00Z","relpermalink":"/post/iv-workshop/","section":"post","summary":"I am co-organising the 1st International Workshop on Socially Interactive Autonomous Mobility (SIAM) at IV 2023. One of the goals of this workshop is to bridge the gap between Computational Cognitive and Behavior Science, Explainable AI, Transportation, and the Autonomous Driving community.","tags":null,"title":"I am co-organising the 1st International Workshop on Socially Interactive Autonomous Mobility (SIAM) at IV 2023","type":"post"},{"authors":["Marc Alexander Kühn","Daniel Omeiza","Lars Kunze"],"categories":null,"content":"","date":1681516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681516800,"objectID":"92c3a9ace65cc0cb88f7a4e0679f178b","permalink":"https://danielomeiza.github.io/publication/001_b_commentary/","publishdate":"2023-04-15T00:00:00Z","relpermalink":"/publication/001_b_commentary/","section":"publication","summary":"The provision of natural language explanations for the predictions of deep-learning-based vehicle controllers is critical as it enhances transparency and easy audit. In this work, a state-of-the-art (SOTA) prediction and explanation model is thoroughly evaluated and validated (as a benchmark) on the new Sense–Assess–eXplain (SAX). Additionally, we developed a new explainer model that improved over the baseline architecture in two ways; (i) an integration of part of speech prediction and (ii) an introduction of special token penalties. On the BLEU metric, our explanation generation technique outperformed SOTA by a factor of 7.7 when applied on the BDD-X dataset. The description generation technique is also improved by a factor of 1.3. Hence, our work contributes to the realisation of future explainable autonomous vehicles.","tags":null,"title":"Textual Explanations for Automated Commentary Driving","type":"publication"},{"authors":["Daniel Omeiza"],"categories":null,"content":"","date":1673568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673827200,"objectID":"cbef6648a14445ddb40c324653161eef","permalink":"https://danielomeiza.github.io/post/postdoc/","publishdate":"2023-01-13T00:00:00Z","relpermalink":"/post/postdoc/","section":"post","summary":"I am working with Dr. Lars Kunze in the Cognitive Robotics group. We are developing new explainability methods for autonomous driving models. We are also exploring ways to ensure resonsible AI using demonstrations from autonomous driving.","tags":null,"title":"I am excited to start as a Post-Doctoral Research Assistant at Oxford","type":"post"},{"authors":["Daniel Omeiza"],"categories":null,"content":"","date":1668643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668643200,"objectID":"aa4fd13c095ca1bc24258647604c5410","permalink":"https://danielomeiza.github.io/post/thesis-submission/","publishdate":"2022-11-17T00:00:00Z","relpermalink":"/post/thesis-submission/","section":"post","summary":"I submitted my DPhil thesis in November 2022. My thesis was on providing intelligible explanations in autonomous driving.","tags":null,"title":"I submitted my DPhil thesis in November 2022","type":"post"},{"authors":["Daniel Omeiza","Sule Anjomshoae","Helena Webb","Marina Jirotka","Lars Kunze"],"categories":null,"content":"","date":1655251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655251200,"objectID":"a42c335a0bf7d5bfe469c7a1803cf591","permalink":"https://danielomeiza.github.io/publication/001_commentary-tree/","publishdate":"2022-06-15T00:00:00Z","relpermalink":"/publication/001_commentary-tree/","section":"publication","summary":"Commentary driving is a technique in which drivers verbalise their observations, assessments and intentions. By speaking out their thoughts, both learning and expert drivers are able to create better understanding and  awareness of their surroundings. In the intelligent vehicles' context, automated driving commentary can provide intelligible explanations about driving actions, and thereby assist a driver or an end-user during driving operations in challenging and safety-critical scenarios. In this paper, we conducted a field study in which we deployed a research vehicle in an urban environment. While collecting sensor data of the vehicle's surroundings, we also recorded a driving instructor using the think-aloud methodology to verbalise their thoughts while driving. We analysed the collected data to uncover necessary requirements for effective explainability in intelligent vehicles. We show how intelligible natural language explanations that fulfil some of the key elicited requirements can be automatically generated based on observed driving data using a simple tree-based approach. Finally, we discuss how our approach can be built on in the future to realise more robust and effective explainability for driver assistance as well as partial and conditional automation of driving functions.","tags":null,"title":"From Spoken Thoughts to Automated Driving Commentary: Predicting and Explaining Intelligent Vehicles' Actions","type":"publication"},{"authors":["Daniel Omeiza","Helena Webb","Marina Jirotka","Lars Kunze"],"categories":null,"content":"","date":1652572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652572800,"objectID":"859c98f3d75a813e8c9c1ab950ba92c5","permalink":"https://danielomeiza.github.io/publication/002_av-survey/","publishdate":"2022-06-15T00:00:00Z","relpermalink":"/publication/002_av-survey/","section":"publication","summary":"The automotive industry has witnessed an increasing level of development in the past decades; from manufacturing manually operated vehicles to manufacturing vehicles with high level of automation. With the recent developments in Artificial Intelligence (AI), automotive companies now employ blackbox AI models to enable vehicles to perceive their environment and make driving decisions with little or no influence from a human. With the hope to deploy autonomous vehicles (AV) on a commercial scale, the acceptance of AV by society becomes paramount and may largely depend on their degree of transparency, trustworthiness, and compliance with regulations. The assessment of these acceptance requirements can be facilitated through the provision of explanations for AVs' behaviour. Explainability is therefore seen as an important requirement for AVs. AVs should be able to explain what they have ‘seen’, done and might do in environments where they operate. In this paper, we provide a comprehensive survey of the existing work in explainable autonomous driving. First, we open by providing a motivation for explanations and examining existing standards related to AVs. Second, we identify and categorise the different stakeholders involved in the development, use, and regulation of AVs and show their perceived need for explanation. Third, we review previous work on explanation in the different AV operations. Finally, we draw a close by pointing out pertinent challenges and future research directions. This survey serves to provide fundamental knowledge required of researchers who are interested in explanation in autonomous driving.","tags":null,"title":"Explanations in Autonomous Driving: A Survey","type":"publication"},{"authors":["Daniel Omeiza","Helena Webb","Marina Jirotka","Lars Kunze"],"categories":null,"content":"","date":1649980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649980800,"objectID":"3242ada6a95d5dc9a67627161f14060f","permalink":"https://danielomeiza.github.io/publication/003_towards-accountability/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/003_towards-accountability/","section":"publication","summary":"The safe deployment of autonomous vehicles (AVs) in real world scenarios requires that AVs are accountable. One way of ensuring accountability is through the provision of explanations for what the vehicles have ‘seen’, done and might do in a given scenario. Intelligible explanations can help developers and regulators to assess AVs' behaviour, and in turn, uphold accountability. In this paper, we propose an interpretable (tree-based) and user-centric approach for explaining autonomous driving behaviours. In a user study, we examined different explanation types instigated by investigatory queries. We conducted an experiment to identify scenarios that require explanations and the corresponding appropriate explanation types for such scenarios. Our findings show that an explanation type matters mostly in emergency and collision driving conditions. Also, providing intelligible explanations (especially contrastive types) with causal attributions can improve accountability in autonomous driving. The proposed interpretable approach can help realise such intelligible explanations with causal attributions.","tags":null,"title":"Towards Accountability: Providing Intelligible Explanations in Autonomous Driving","type":"publication"},{"authors":["Richa Nahata","Daniel Omeiza","Rhys Howard","Lars Kunze"],"categories":null,"content":"","date":1647302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647302400,"objectID":"7fb4d31bfd74ca1c176090cb76ab4983","permalink":"https://danielomeiza.github.io/publication/004_collision-risk/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/publication/004_collision-risk/","section":"publication","summary":"Autonomous vehicles operating in dynamic environments are required to account for other traffic participants. By interpreting sensor information and assessing the collision risk with vehicles, cyclists, and pedestrians, near-misses and accidents can be prevented. Moreover, by explaining risk factors to developers and engineers the overall safety of autonomous driving can be increased in future deployments. In this paper, we have designed, developed, and evaluated an approach for predicting the collision risk with other road users based on a planar 2D collision model. To this end, we have trained interpretable machine learning models to classify and predict the risk of collisions on a range of features extracted from sensor data. Further, we present methods for inferring and explaining the factors mostly contributing to the risk. Using counterfactual inference, our approach allows us to determine the factors which highly influence the risk and should in turn be minimised. Experimental results on real-world driving data show that collision risk can be effectively predicted and explained for different time horizons as well as different types of traffic participants such as cars, cyclists and pedestrians.","tags":null,"title":"Assessing and Explaining Collision Risk in Dynamic Environments forAutonomous Driving Safety","type":"publication"},{"authors":["Daniel Omeiza","Helena Webb","Konrad Kollnig","Marina Jirotka","Lars Kunze"],"categories":null,"content":"","date":1644883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644883200,"objectID":"fe0d85ca09a049de84c05d18b95c1529","permalink":"https://danielomeiza.github.io/publication/005_trust/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/publication/005_trust/","section":"publication","summary":"Autonomous vehicles (AVs) have the potential to change the way we commute, travel, and transport our goods. The deployment of AVs in society, however, requires that people understand, accept, and trust them. Intelligible explanations can help different AV stakeholders to assess AVs' behaviours, and in turn, increase their confidence and foster trust. In a user study (N = 101), we examined different explanation types (based on investigatory queries) provided by an AV and their effect on people using the trust determinant factors. Our quantitative and qualitative analysis shows that explanations with causal attributions improved task performance and understanding when assessing driving events but did not directly improve perceived trust. This underlines the potential need for additional measures and research to enhance trust in AVs.","tags":null,"title":"Why Not Explain? Effects of Explanations on Human Perceptions of Autonomous Driving","type":"publication"},{"authors":["Sule Anjomshoae","Daniel Omeiza","Lili Jang"],"categories":null,"content":"","date":1642204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642204800,"objectID":"11f1f86ce33a2b3ba28ca27b088aea7f","permalink":"https://danielomeiza.github.io/publication/006_cicu/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/006_cicu/","section":"publication","summary":"With the increased use of machine learning in decision-making scenarios, there has been a growing interest in explaining and understanding the outcomes of machine learning models. Despite this growing interest, the existing works on interpretability and explanations have been mostly intended for expert users. Explanations for end-users have been neglected in many usable and practical applications (e.g., image tagging, caption generation). It is important for non-expert users to understand features and how they affect an instance-specific prediction to satisfy the need for justification. In this paper, we propose a model-agnostic method for generating context-based explanations aiming for general users. We implement partial occlusion on segmented components to identify the contextual importance of each segment in scene classification tasks. We then generate explanations based on feature importance in a given context. We present visual and text-based explanations: (i) saliency map presents the pertinent components with a descriptive textual justification, (ii) visual map with a color bar graph showing the relative importance of each feature for a prediction. Evaluating the explanations using a user study (N=50), we observed that our proposed explanation methods outperformed existing gradient and masking based methods. Hence, our proposed explanation method could be deployed to explain models' decisions in real-world applications.","tags":null,"title":"Context-based Image Explanations for Deep Neural Networks","type":"publication"},{"authors":["Daniel Omeiza","Sule Anjomshoae","Konrad Kollnig","Oana-Maria Camburu","Kary Framling","Lars Kunze"],"categories":null,"content":"","date":1642118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642118400,"objectID":"36e46f41397bdf8489bbcdc7915e47b6","permalink":"https://danielomeiza.github.io/publication/007_chi-workshop/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/007_chi-workshop/","section":"publication","summary":"The safe deployment of autonomous physical systems in real-world scenarios requires them to be explainable and trustworthy, especially in critical domains. In contrast with `black-box' systems, explainable and trustworthy autonomous physical systems will lend themselves to easy assessments by system designers and regulators. This promises to pave ways for easy improvements that can lead to enhanced performance, and as well, increased public trust. In this one-day virtual workshop, we aim to gather a globally distributed group of researchers and practitioners to discuss the opportunities and  social challenges in the design, implementation, and deployment of explainable and trustworthy autonomous physical systems, especially in a post-pandemic era. Interactions will be fostered through panel discussions and a series of spotlight talks. To ensure lasting impact of the workshop, we will conduct a pre-workshop survey which will examine the public perception of the trustworthiness of autonomous physical systems. Further, we will publish a summary report providing details about the survey as well as the identified challenges resulting from the workshop's panel discussions.","tags":null,"title":"Towards Explainable and Trustworthy Autonomous Physical Systems","type":"publication"},{"authors":["Damiel Omeiza","Celia Cintas","Skyler Speakman","Komminist Weldermariam"],"categories":null,"content":"","date":1637020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637020800,"objectID":"1915585d47443b557d3b0118cd4c394f","permalink":"https://danielomeiza.github.io/publication/008_smooth-grad/","publishdate":"2021-01-15T00:00:00Z","relpermalink":"/publication/008_smooth-grad/","section":"publication","summary":"Gaining insight into how deep convolutional neural network models perform image classification and how to explain their outputs have been a concern to computer vision researchers and decision makers. These deep models are often referred to as black box due to low comprehension of their internal workings. As an effort to developing explainable deep learning models, several methods have been proposed such as finding gradients of class output with respect to input image (sensitivity maps), class activation map (CAM), and Gradient based Class Activation Maps (Grad-CAM). These methods under perform when localizing multiple occurrences of the same class and do not work for all CNNs. In addition, Grad-CAM does not capture the entire object in completeness when used on single object images, this affect performance on recognition tasks. With the intention to create an enhanced visual explanation in terms of visual sharpness, object localization and explaining multiple occurrences of objects in a single image, we present Smooth Grad-CAM++, a technique that combines methods from two other recent techniques---SMOOTHGRAD and Grad-CAM++. Our Smooth Grad-CAM++ technique provides the capability of either visualizing a layer, subset of feature maps, or subset of neurons within a feature map at each instance at the inference level (model prediction process). After  experimenting with few images, Smooth Grad-CAM++ produced more visually sharp maps with better localization of objects in the given input images when compared with other methods.","tags":null,"title":"Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models","type":"publication"},{"authors":["Konrad Kollnig","Reuben Binns","Pierre Dewitte","Max Van Kleek","Ge Wang","Daniel Omeiza","Helena Webb","Nigel Shadbolt"],"categories":null,"content":"","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636934400,"objectID":"327a120cbf04437f6359061a007ca492","permalink":"https://danielomeiza.github.io/publication/009_tracking/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/009_tracking/","section":"publication","summary":"Third-party tracking allows companies to collect users' behavioural data and track their activity across digital devices. This can put deep insights into users' private lives into the hands of strangers, and often happens without users' awareness or explicit consent. EU and UK data protection law, however, requires consent, both 1) to access and store information on users' devices and 2) to legitimate the processing of personal data as part of third-party tracking, as we analyse in this paper. This paper further investigates whether and to what extent consent is implemented in mobile apps. First, we analyse a representative sample of apps from the Google Play Store. We find that most apps engage in third-party tracking, but few obtained consent before doing so, indicating potentially widespread violations of EU and UK privacy law. Second, we examine the most common third-party tracking libraries in detail. While most acknowledge that they rely on app developers to obtain consent on their behalf, they typically fail to put in place robust measures to ensure this: disclosure of consent requirements is limited; default consent implementations are lacking; and compliance guidance is difficult to find, hard to read, and poorly maintained.","tags":null,"title":"A Fait Accompli? An Empirical Study into the Absence of Consent to Third-Party Tracking in Android Apps","type":"publication"},{"authors":["Charity Delmus Alupo","Daniel Omeiza","David Vernon"],"categories":null,"content":"","date":1634256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634256000,"objectID":"ec1275ad99bc0fcba304fdf50b41bbf7","permalink":"https://danielomeiza.github.io/publication/0091_ai-trust-in-africa/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/publication/0091_ai-trust-in-africa/","section":"publication","summary":"Most\tnations\thave\trecognized\tthe\tdisruptive\tinfluence\tof\tartificial\tintelligence\t(AI)\ton\tall aspects\t of\t their\t economies,\t from\t manufacturing,\t to\t services,\t to\t governance,\t and\t the\t potential benefits\tthat\tembracing\tAI\ttechnologies\tcan\tbring.\tIt\tis\tno\tdifferent\tin\tdeveloping\tcountries\tand\tit is\tcertainly\tthe\tcase\tthat\tthe\tcountries\tof\tAfrica\thave\tembraced\tAI,\tdata\tscience,\tmachine\tlearning, and\trobotics.\tHowever,\tthe\ttransition\tfrom\trecognition\tof\tpotential\tto\trealization\tof\tbenefits\tis\tnot a\t straightforward\t matter.\t In\t this\t essay,\t we\t argue\t that\t this\t transition\t depends\t on\t turning technological\t invention\t into\t innovation,\t that\t technological\t innovation\t cannot\t happen\t without adoption,\t and\t that\t adoption\t depends\t on\t socio-cultural\t factors,\t in\t general,\t and\t on\t trust,\t in particular.\tWe\tdraw\tout\tthe\timplications\tfor\tAI\tin\tdeveloping\tcountries\tin\tAfrica,\targuing\tthat,\tfor Africa\tto\trealize\tthe\tpotential\tof\tAI\tin\tsolving\teconomic\tand\tsocial\tproblems,\tthe\tadvancement\tand deployment\tof\tAI\tmust\tbe\tdriven\tand\texecuted\tby\tthe\tpeoples\tof\tAfrica:\tif\tit\tis\tnot,\tthere\twill\tbe little\ttrust,\tless\tadoption,\tand\tminimal\tbenefits.","tags":null,"title":"Realizing the Potential of AI in Africa: It All Turns on Trust","type":"publication"},{"authors":["Daniel Omeiza"],"categories":null,"content":"","date":1631664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631664000,"objectID":"99cb31d9466fff52048fa5c52da822ed","permalink":"https://danielomeiza.github.io/publication/0092_remote-sensing/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/0092_remote-sensing/","section":"publication","summary":"Urbanization is a common phenomenon in developing countries and it poses serious challenges when not managed effectively. Lack of proper planning and management may cause the encroachment of urban fabrics into reserved or special regions which in turn can lead to an unsustainable increase in population. Ineffective management and planning generally leads to depreciated standard of living, where physical hazards like traffic accidents and disease vector breeding become prevalent. In order to support urban planners and policy makers in effective planning and accurate decision making, we investigate urban land-use in sub-Saharan Africa. Land-use dynamics serves as a crucial parameter in current strategies and policies for natural resource management and monitoring. Focusing on Nairobi, we use an efficient deep learning approach with patch-based prediction to classify regions based on land-use from 2004 to 2018 on a quarterly basis. We estimate changes in land-use within this period, and using the Autoregressive Integrated Moving Average (ARIMA) model, our results forecast land-use for a given future date. Furthermore, we provide labelled land-use maps which will be helpful to urban planners.","tags":["Source Themes"],"title":"Efficient Machine Learning for Large-Scale Urban Land-Use Forecasting in Sub-Saharan Africa","type":"publication"},{"authors":["Daniel Nkemelu","Daniel Omeiza","Nancy Lubalo"],"categories":null,"content":"","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"ebe72cb34ce61dd1c319ac0a2e0de945","permalink":"https://danielomeiza.github.io/publication/0093_leaf_detection/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/0093_leaf_detection/","section":"publication","summary":"Agriculture is vital for human survival and remains a major driver of several economies around the world; more so in underdeveloped and developing economies. With increasing demand for food and cash crops, due to a growing global population and the challenges posed by climate change, there is a pressing need to increase farm outputs while incurring minimal costs. Previous machine vision technologies developed for selective weeding have faced the challenge of reliable and accurate weed detection. We present approaches for plant seedlings classification with a dataset that contains 4,275 images of approximately 960 unique plants belonging to 12 species at several growth stages. We compare the performances of two traditional algorithms and a Convolutional Neural Network (CNN), a deep learning technique widely applied to image recognition, for this task. Our findings show that CNN-driven seedling classification applications when used in farming automation has the potential to optimize crop yield and improve productivity and efficiency when designed appropriately.","tags":null,"title":"Deep Convolutional Neural Network for Plant Seedlings Classification","type":"publication"},{"authors":["Daniel Omeiza","Kayode Adewole","Daniel Nkemelu"],"categories":null,"content":"","date":1626307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626307200,"objectID":"70e3a95b6b1e767628f3d87046a0f782","permalink":"https://danielomeiza.github.io/publication/0094_eeg-/","publishdate":"2018-11-01T00:00:00Z","relpermalink":"/publication/0094_eeg-/","section":"publication","summary":"Several changes occur in the brain in response to voluntary and involuntary activities performed by a person. The ability to retrieve data from the brain within a time space provides a basis for in-depth analyses that offer insight on what changes occur in the brain during its decision-making processes. In this work, we present the technical description and software implementation of an electroencephalographic (EEG) based communication system. We read EEG data in real-time with which we compute the likelihood that a voluntary eye blink has been made by a person and use the decision to trigger buttons on a user interface in order to produce text. Relevant texts are suggested using a modification of the T9 algorithm. Our results indicate that EEG-based technology can be effectively applied in facilitating speech for people with severe speech and muscular disabilities, providing a foundation for future work in the area.","tags":["Source Themes"],"title":"EEG-based Communication with a Predictive Text Algorithm","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://danielomeiza.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]